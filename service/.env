LLM_MODEL = "qwen"  # Or any llm you can call
llm = oxy.HttpLLM(
    name=LLM_MODEL,
    api_key=get_env_var("sk-f5fda4d46d59461c95b66147e1c39c38"), # Do not forget set in .env
    base_url=get_env_var("https://dashscope.aliyuncs.com/compatible-mode/v1"),
    model_name=get_env_var("qwen-plus"),
    llm_params={"temperature": 0.01},
    semaphore=4, #最多允许4个并发请求
    max_tokens = 4096 - 1024, #模型最大上下文长度4096，预留1024给agent
)